{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/natelo/Downloads/XTern_AI_Data.csv\") #use your own path\n",
    "\n",
    "#Convert the raw data to numerical, processable by the machine learning model\n",
    "converted_data = data.copy()\n",
    "\n",
    "year_mapping = {'Year 1': 1, 'Year 2': 2, 'Year 3': 3, 'Year 4': 4}\n",
    "unique_majors = data['Major'].unique()\n",
    "unique_universities = data['University'].unique()\n",
    "unique_orders = data['Order'].unique()\n",
    "\n",
    "major_mapping = {value: index for index, value in enumerate(unique_majors)}\n",
    "uni_mapping = {value: index for index, value in enumerate(unique_universities)}\n",
    "order_mapping = {value: index for index, value in enumerate(unique_orders)}\n",
    "\n",
    "converted_data['Year'] = data['Year'].map(year_mapping)\n",
    "converted_data['Major'] = data['Major'].map(major_mapping)\n",
    "converted_data['University'] = data['University'].map(uni_mapping)  \n",
    "converted_data['Order'] = data['Order'].map(order_mapping)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.037719171576576\n",
      "Mean Absolute Error: 1.5914834405257916\n",
      "R-squared (R2): 0.41241796701885736\n",
      "Cross-Validation Scores (Mean Squared Error): [4.88999315 4.92735459 4.72780535 4.89377206 5.35770691]\n",
      "Mean MSE: 4.9593264112851925\n"
     ]
    }
   ],
   "source": [
    "X = converted_data[['University', 'Major', 'Year', 'Time']]\n",
    "y = converted_data['Order']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting data in training and testing sets. 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)\n",
    "\n",
    "#Train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=52)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Test analytics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared (R2): {r2}\")\n",
    "\n",
    "#cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores\n",
    "print(\"Cross-Validation Scores (Mean Squared Error):\", mse_scores)\n",
    "print(\"Mean MSE:\", mse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to pickle the model:\n",
    "# download_path = \"/------\"  #create a path to download the model\n",
    "# filename = 'random_forest_model.pkl'\n",
    "# file_path = os.path.join(download_path, filename)\n",
    "# with open(file_path, 'wb') as model_file:\n",
    "#     pickle.dump(model, model_file)\n",
    "\n",
    "# # check if the file exists in the directory\n",
    "# if os.path.exists(file_path):\n",
    "#     print(\"File exists!\")\n",
    "# else:\n",
    "#     print(\"File does not exist.\")\n",
    "    \n",
    "#the attached .pkl file is the model that was trained on the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
